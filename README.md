# Gradient Descent in Logistic Regression

## ðŸš€ Overview
Gradient Descent is a fundamental optimization algorithm used to minimize the loss function of a model by iteratively adjusting its parameters. In Logistic Regression, Gradient Descent is critical for optimizing weights and biases to identify the decision boundary that best separates the classes. In Logistic Regression, the model predicts the probability of a binary outcome using the sigmoid function.The objective is to minimize the log-loss (cross-entropy loss)

## ðŸ”„ Implementations: With and Without Momentum
We have implemented two variants of Gradient Descent in this project 

- Without Momentum: Parameters are updated solely based on the gradient of the loss function at each step.
- With Momentum: Momentum introduces an additional term that considers the previous update to accelerate convergence and reduce oscillations.


